{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "## Step 1: Exploring your data.\n",
    "\n",
    "##### Load your data in using Pandas and start to explore. Save all of your early exploration code here and include in your final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stav/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 83 columns):\n",
      "year               317 non-null int64\n",
      "artist.inverted    317 non-null object\n",
      "track              317 non-null object\n",
      "time               317 non-null object\n",
      "genre              317 non-null object\n",
      "date.entered       317 non-null object\n",
      "date.peaked        316 non-null object\n",
      "x1st.week          317 non-null int64\n",
      "x2nd.week          312 non-null float64\n",
      "x3rd.week          307 non-null float64\n",
      "x4th.week          300 non-null float64\n",
      "x5th.week          292 non-null float64\n",
      "x6th.week          280 non-null float64\n",
      "x7th.week          269 non-null float64\n",
      "x8th.week          260 non-null float64\n",
      "x9th.week          253 non-null float64\n",
      "x10th.week         244 non-null float64\n",
      "x11th.week         236 non-null float64\n",
      "x12th.week         222 non-null float64\n",
      "x13th.wek          210 non-null float64\n",
      "x14th.week         204 non-null float64\n",
      "x15th.week         197 non-null float64\n",
      "x16th.week         182 non-null float64\n",
      "x17th.week         177 non-null float64\n",
      "x18th.week         166 non-null float64\n",
      "x19th.week         156 non-null float64\n",
      "x20th.week         146 non-null float64\n",
      "x21st.week         65 non-null float64\n",
      "x22nd.week         55 non-null float64\n",
      "x23rd.week         48 non-null float64\n",
      "x24th.week         46 non-null float64\n",
      "x25th.week         38 non-null float64\n",
      "x26th.week         36 non-null float64\n",
      "x27th.week         29 non-null float64\n",
      "x28th.week         24 non-null float64\n",
      "x29th.week         20 non-null float64\n",
      "x30th.week         20 non-null float64\n",
      "x31st.week         19 non-null float64\n",
      "x32nd.week         18 non-null float64\n",
      "x33rd.week         12 non-null float64\n",
      "x34th.week         10 non-null float64\n",
      "x35th.week         9 non-null float64\n",
      "x36th.week         9 non-null float64\n",
      "x37th.week         9 non-null float64\n",
      "x38th.week         8 non-null float64\n",
      "x39th.week         8 non-null float64\n",
      "x40th.week         7 non-null float64\n",
      "x41st.week         7 non-null float64\n",
      "x42nd.week         6 non-null float64\n",
      "x43rd.week         6 non-null float64\n",
      "x44th.week         6 non-null float64\n",
      "x45th.week         5 non-null float64\n",
      "x46th.week         5 non-null float64\n",
      "x47th.week         5 non-null float64\n",
      "x48th.week         4 non-null float64\n",
      "x49th.week         4 non-null float64\n",
      "x50th.week         4 non-null float64\n",
      "x51st.week         4 non-null float64\n",
      "x52nd.week         4 non-null float64\n",
      "x53rd.week         4 non-null float64\n",
      "x54th.week         2 non-null float64\n",
      "x55th.week         2 non-null float64\n",
      "x56th.week         2 non-null float64\n",
      "x57th.week         2 non-null float64\n",
      "x58th.week         2 non-null float64\n",
      "x59th.week         2 non-null float64\n",
      "x60th.week         2 non-null float64\n",
      "x61st.week         2 non-null float64\n",
      "x62nd.week         2 non-null float64\n",
      "x63rd.week         2 non-null float64\n",
      "x64th.week         2 non-null float64\n",
      "x65th.week         1 non-null float64\n",
      "x66th.week         0 non-null float64\n",
      "x67th.week         0 non-null float64\n",
      "x68th.week         0 non-null float64\n",
      "x69th.week         0 non-null float64\n",
      "x70th.week         0 non-null float64\n",
      "x71st.week         0 non-null float64\n",
      "x72nd.week         0 non-null float64\n",
      "x73rd.week         0 non-null float64\n",
      "x74th.week         0 non-null float64\n",
      "x75th.week         0 non-null float64\n",
      "x76th.week         0 non-null float64\n",
      "dtypes: float64(75), int64(2), object(6)\n",
      "memory usage: 205.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv(\"../assets/billboard.csv\") #reading data set in\n",
    "#print billboard.tail()\n",
    "print billboard.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a data dictionary for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'genre': 'genre name 317', 'date.peaked': 'date with the highest billboard score 316', 'x1st.week-x76th': 'score since week released 317', 'year': 'Year the song was released 317', 'track': 'track name 317', 'time': 'song length 317', 'artist.inverted': '', 'date.entered': 'date entered into billboard 317'}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'year': 'Year the song was released 317',\n",
    "'artist.inverted':'' ,  \n",
    "'track':'track name 317',           \n",
    "'time':'song length 317',            \n",
    "'genre':'genre name 317',            \n",
    "'date.entered':'date entered into billboard 317',    \n",
    "'date.peaked':'date with the highest billboard score 316',    \n",
    "'x1st.week-x76th':'score since week released 317'}\n",
    "print data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write a brief description of your data, and any interesting observations you've made thus far. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Analyzing the latest generation's guilty pleasure- the music of the '00s. Our Data Scientists have poured through Billboard chart data to analyze what made a hit soar to the top of the charts, and how long they stayed there. Tune in next week for an awesome exploration of music and data as we continue to address an omnipresent quandary in the industry- why do we like what we like?\n",
    "\n",
    "['year' 'artist.inverted' 'track' 'time' 'genre' 'date.entered'\n",
    " 'date.peaked' 'x1st.week' 'x2nd.week']\n",
    "\n",
    "interesting findings: Theres lots of different genres and even the Thong song from the famous rapper sisqo. Looks like the weeks refer to how many weeks the particular song has been on the billboard and what is the ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do some rudimentary cleaning. Rename any columns that are poorly named, shorten any strings that may be too long, fill in any missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>genre</th>\n",
       "      <th>date_entered</th>\n",
       "      <th>date_peaked</th>\n",
       "      <th>x1st_week</th>\n",
       "      <th>x2nd_week</th>\n",
       "      <th>x3rd_week</th>\n",
       "      <th>...</th>\n",
       "      <th>x67th_week</th>\n",
       "      <th>x68th_week</th>\n",
       "      <th>x69th_week</th>\n",
       "      <th>x7th_week</th>\n",
       "      <th>x71st_week</th>\n",
       "      <th>x72nd_week</th>\n",
       "      <th>x73rd_week</th>\n",
       "      <th>x74th_week</th>\n",
       "      <th>x75th_week</th>\n",
       "      <th>x76th_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Destiny's Child</td>\n",
       "      <td>Independent Women Part I</td>\n",
       "      <td>3:38</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-09-23</td>\n",
       "      <td>2000-11-18</td>\n",
       "      <td>78</td>\n",
       "      <td>63.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Santana</td>\n",
       "      <td>Maria, Maria</td>\n",
       "      <td>4:18</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-02-12</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Savage Garden</td>\n",
       "      <td>I Knew I Loved You</td>\n",
       "      <td>4:07</td>\n",
       "      <td>Rock</td>\n",
       "      <td>1999-10-23</td>\n",
       "      <td>2000-01-29</td>\n",
       "      <td>71</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Madonna</td>\n",
       "      <td>Music</td>\n",
       "      <td>3:45</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>2000-09-16</td>\n",
       "      <td>41</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Aguilera, Christina</td>\n",
       "      <td>Come On Over Baby (All I Want Is You)</td>\n",
       "      <td>3:38</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>2000-10-14</td>\n",
       "      <td>57</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year               artist                                  track  time  \\\n",
       "0  2000      Destiny's Child               Independent Women Part I  3:38   \n",
       "1  2000              Santana                           Maria, Maria  4:18   \n",
       "2  2000        Savage Garden                     I Knew I Loved You  4:07   \n",
       "3  2000              Madonna                                  Music  3:45   \n",
       "4  2000  Aguilera, Christina  Come On Over Baby (All I Want Is You)  3:38   \n",
       "\n",
       "  genre date_entered date_peaked  x1st_week  x2nd_week  x3rd_week     ...      \\\n",
       "0  Rock   2000-09-23  2000-11-18         78       63.0       49.0     ...       \n",
       "1  Rock   2000-02-12  2000-04-08         15        8.0        6.0     ...       \n",
       "2  Rock   1999-10-23  2000-01-29         71       48.0       43.0     ...       \n",
       "3  Rock   2000-08-12  2000-09-16         41       23.0       18.0     ...       \n",
       "4  Rock   2000-08-05  2000-10-14         57       47.0       45.0     ...       \n",
       "\n",
       "   x67th_week  x68th_week  x69th_week  x7th_week  x71st_week  x72nd_week  \\\n",
       "0         NaN         NaN         NaN        NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN        NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN        NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN        NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN        NaN         NaN         NaN   \n",
       "\n",
       "   x73rd_week  x74th_week  x75th_week  x76th_week  \n",
       "0         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard = pd.read_csv('../assets/billboard.csv')\n",
    "import string \n",
    "print(string.ascii_lowercase) #print alphabet\n",
    "billboard.columns = [\n",
    "    ''.join([\n",
    "            y for y in x.lower() \n",
    "            if y in string.ascii_lowercase+' '+'123456789'+'.'    # filter only allow if y in alphabet or ' ' or integers or ., replace it\n",
    "        ]).replace(' ','_').replace('.','_')\n",
    "    for x in billboard.columns\n",
    "]\n",
    "billboard\n",
    "\n",
    "        \n",
    "billboard = billboard.rename(columns = {'artist_inverted':'artist'})    #rename column as artist\n",
    "billboard.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Pandas' built in `melt` function, pivot the weekly ranking data to be long rather than wide. As a result, you will have removed the 72 'week' columns and replace it with two: Week and Ranking. There will now be multiple entries for each song, one for each week on the Billboard rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weeks = pd.Series(billboard.columns.values)\n",
    "\n",
    "subset_long = 1\n",
    "# new = [int(s) for s in 'x1stweek'.split() if s.isdigit()]\n",
    "# new\n",
    "            \n",
    "            \n",
    "            \n",
    "#subset_long = pd.melt(billboard, id_vars = ['track','artist','genre'])\n",
    "                  \n",
    "# subset_long = pd.melt(billboard, id_vars = ['track','artist','genre'], value_vars = weeks[7:], var_name='week',\n",
    "#                       value_name='ranking')\n",
    "\n",
    "\n",
    "# subset_long.describe()\n",
    "# print subset_long\n",
    "\n",
    "# subset_new = subset_long[['track','artist','value']]\n",
    "#         #var_name='variable',#             value_name='value')\n",
    "# print subset_new.shape\n",
    "# subset_new.index = subset_long['variable']\n",
    "# subset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "week1 = subset_long[subset_long['week'] == 'x1st.week']\n",
    "print week1.columns    #how our billboard stacks for week 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using a plotting utility of your choice, create visualizations that will provide context to your data. There is no minimum or maximum number of graphs you should generate, but there should be a clear and consistent story being told. Give insights to the distribution, statistics, and relationships of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (8, 8)})\n",
    "g = sns.distplot(week1.ranking,50)\n",
    "g.set_title('Week1 Billboard Distribution')\n",
    "g.set_xlabel('Ranking')\n",
    "g.set_ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# week 1 sorted ranking now write function to get data on all weeks for these songs\n",
    "\n",
    "print 'worst:',week1.sort('ranking', ascending = False).head(10), '\\n''\\n''\\n'\n",
    "print 'best:', week1.sort('ranking', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Problem Statement.\n",
    "\n",
    "##### Having explored the data, come up with a problem statement for this data set. You can feel free to introduce data from any other source to support your problem statement, just be sure to provide a link to the origin of the data. Once again- be creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in weeks:\n",
    "    week = subset_long[subset_long['week'] == i]\n",
    "    #print week\n",
    "    print week.sort('ranking', ascending = True).head(5)[['track','artist','ranking', 'week']]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### average rating of genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 5: Brainstorm your Approach.\n",
    "##### In bullet-list form, provide a proposed approach for evaluating your problem statement. This can be somewhat high-level, but start to think about ways you can massage the data for maximum efficacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 6: Create a blog post with your code snippets and visualizations.\n",
    "##### Data Science is a growing field, and the Tech industry thrives off of collaboration and sharing of knowledge. Blogging is a powerful means for pushing the needle forward in our field. Using your blogging platform of choice, create a post describing each of the 5 steps above. Rather than writing a procedural text, imagine you're describing the data, visualizations, and conclusions you've arrived at to your peers. Aim for roughly 800-1,000 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: The Content Managers working for the Podcast Publishing Company have recognized you as a thought leader in your field. They've asked you to pen a white paper (minimum 600 words) on the subject of 'What It Means To Have Clean Data'. This will be an opinion piece read by a wide audience, so be sure to back up your statements with real world examples or scenarios.\n",
    "\n",
    "##### Hint: To get started, look around on the internet for articles, blog posts, papers, youtube videos, podcasts, reddit discussions, anything that will help you understand the challenges and implications of dealing with big data. This should be a personal reflection on everything you've learned this week, and the learning goals that have been set out for you going forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
